========================================
  V4.0 搜索超时和浏览器关闭错误 - 已修复
========================================

【问题1：搜索结果页面加载超时】

错误信息：
  [bold red]错误：加载搜索结果页面超时。[/bold red]
  [yellow]可能是网络问题或反爬机制。[/yellow]
  已保存截图: D:\xiaohongshu-crawler\output\debug\search_timeout_yan-jing.png

原因：
  1. 单一搜索URL可能失效
  2. 页面等待时间不够长
  3. 选择器可能不准确

修复：
  1. 尝试多个搜索URL
  2. 使用多种选择器
  3. 增加页面加载超时时间（60秒 → 90秒）
  4. 添加更详细的错误信息

---

【问题2：采集到0篇笔记】

原因：
  搜索页面加载失败，没有收集到任何链接

修复：
  1. 改进搜索URL列表
  2. 尝试多种页面选择器
  3. 保存调试信息（截图+HTML）
  4. 添加更详细的日志

---

【问题3：浏览器关闭错误】

错误信息：
  playwright._impl._errors.Error: Event loop is closed! Is Playwright already stopped?

原因：
  browser变量在with sync_playwright()块外部使用
  当finally块执行时，playwright已经关闭

修复：
  将browser.close()移到with块内部

---

【修复详情】

1. search_and_collect_urls() 函数
   - 尝试多个搜索URL
   - 使用多种选择器
   - 增加超时时间
   - 保存调试信息

2. crawl_keyword() 函数
   - 使用更宽松的链接选择器
   - 改进链接收集逻辑

3. main() 函数
   - 修复browser.close()位置
   - 改进错误处理
   - 添加更多调试信息

---

【搜索URL列表】

尝试以下URL（按顺序）：

1. https://www.xiaohongshu.com/search_result?keyword={keyword}
2. https://www.xiaohongshu.com/search_result?keyword={keyword}&source=web_search&type=note
3. https://www.xiaohongshu.com/search_result?keyword={keyword}&type=51
4. https://www.xiaohongshu.com/web/search/result?keyword={keyword}

---

【页面选择器】

尝试以下选择器（按顺序）：

1. div[id*='exploreFeeds']
2. .feeds-container
3. .search-result
4. [class*='feeds']
5. [class*='feed']
6. .note-list

---

【调试信息保存位置】

output/debug/
├── search_failed_yan-jing.png
└── search_failed_yan-jing.html

如果所有URL都失败，会保存当前页面状态

---

【可能的解决方案】

1. 检查网络连接
   - 确保网络稳定
   - 检查是否可以访问小红书

2. 检查登录状态
   - 删除 cookies.json
   - 重新登录
   - 确保登录成功

3. 增加延迟时间
   编辑 .env 文件
   SLEEP_BETWEEN_REQUESTS=5.0
   SLEEP_BETWEEN_SCROLLS=2.0

4. 使用无头模式
   HEADLESS=False（显示浏览器）

5. 查看调试信息
   - 查看截图，看是否有验证码
   - 查看HTML，分析页面结构

---

【测试步骤】

1. 删除cookies.json
2. 重新登录
3. 运行爬虫
4. 观察日志输出
5. 查看调试信息（如果失败）

---

【日志分析】

成功加载：
  [green]搜索结果页面加载成功。[/green]

加载失败：
  [bold red]错误：所有搜索URL都无法加载。[/bold red]
  [yellow]可能是网络问题、反爬机制或页面结构变化。[/yellow]

收集链接：
  [keyword] 最终收集到 X 个链接

采集笔记：
  [keyword] [green]成功解析 X 篇笔记[/green]

---

【完整配置】

.env 文件：

# 搜索关键词
KEYWORDS=眼镜

# 目标采集数量
TARGET_COUNT=100

# 页面加载超时（秒）- 可以增加
PAGE_LOAD_TIMEOUT=90

# 是否使用无头模式
HEADLESS=False

# 请求之间的延迟（秒）- 可以增加
SLEEP_BETWEEN_REQUESTS=3.5

# 滚动之间的延迟（秒）- 可以增加
SLEEP_BETWEEN_SCROLLS=1.5

# 输出目录
OUTPUT_DIR=output

# 调试信息目录
DEBUG_DIR=output/debug

# Cookies文件路径
COOKIES_FILE=cookies.json

# 登录超时时间（秒）- 默认600秒（10分钟）
LOGIN_TIMEOUT=600

---

【调试技巧】

1. 查看截图
   - 检查是否有验证码
   - 检查是否是登录页面
   - 检查页面是否正常加载

2. 查看HTML
   - 检查选择器是否正确
   - 检查页面结构是否变化
   - 检查是否有笔记链接

3. 分析日志
   - 哪一步失败了
   - 错误信息是什么
   - 如何修复

---

【如果还是失败】

1. 使用V2版本
   - 更快但风险较高
   - 可以测试是否是V4的问题

2. 手动测试
   - 手动访问小红书
   - 搜索关键词
   - 检查是否能正常浏览

3. 等待一段时间
   - 小红书可能限制了访问
   - 等待24小时后再试

4. 更换账号
   - 使用不同账号登录
   - 建议使用小号

---

【文件更新】

修改的文件：
  - crawler_v4.py    (20K) - 修复搜索和关闭问题

新增文档：
  - 搜索超时修复.txt - 本文件

---

【验证修复】

1. 语法检查
   python -m py_compile crawler_v4.py

   结果：✓ Syntax OK

2. 运行测试
   python crawler_v4.py

   应该看到：
   - 尝试多个搜索URL
   - 如果全部失败，保存调试信息
   - 不会出现浏览器关闭错误

---

【相关文档】

- 登录退出问题修复.txt - 之前的修复
- 登录更新说明.md - 登录优化
- 修复完成.md - 之前的修复
- README_FINAL.md - 完整说明

========================================
  修复完成
========================================

【修复内容】

1. ✓ 搜索超时 - 尝试多个URL
2. ✓ 0篇笔记 - 改进搜索逻辑
3. ✓ 浏览器关闭错误 - 修复作用域

【可以测试】

运行：
  python crawler_v4.py

或双击：
  start_v4.py

========================================
