"""
å°çº¢ä¹¦çˆ¬è™« - æœç´¢çœ¼é•œç›¸å…³ç¬”è®°å¹¶ä¿å­˜æ ‡é¢˜å’Œæ­£æ–‡
"""
import asyncio
import json
import time
import random
import os
import sys
import io
from datetime import datetime
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError
from config import Config

# è®¾ç½®UTF-8ç¼–ç ï¼ˆWindowså…¼å®¹ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')


class XiaohongshuCrawler:
    def __init__(self):
        self.notes = []
        self.browser = None
        self.context = None
        self.page = None
        
    async def init(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        playwright = await async_playwright().start()
        self.browser = await playwright.chromium.launch(
            headless=Config.HEADLESS,
            args=Config.BROWSER_ARGS
        )
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¿å­˜çš„cookies
        if os.path.exists(Config.COOKIE_FILE):
            with open(Config.COOKIE_FILE, 'r', encoding='utf-8') as f:
                cookies = json.load(f)
        else:
            cookies = []
        
        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
        self.context = await self.browser.new_context(
            user_agent=Config.USER_AGENT,
            viewport={'width': 1920, 'height': 1080},
            storage_state={'cookies': cookies}
        )
        
        self.page = await self.context.new_page()
        
        # æ³¨å…¥åæ£€æµ‹è„šæœ¬
        await self.page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });
            
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en']
            });
        """)
    
    async def save_cookies(self):
        """ä¿å­˜cookies"""
        cookies = await self.context.cookies()
        with open(Config.COOKIE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cookies, f, ensure_ascii=False, indent=2)
        print(f"âœ“ Cookieså·²ä¿å­˜åˆ° {Config.COOKIE_FILE}")
    
    async def check_login_status(self):
        """æ£€æŸ¥æ˜¯å¦å·²ç™»å½•"""
        await self.page.goto("https://www.xiaohongshu.com/")
        await asyncio.sleep(3)
        
        try:
            # æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰ç™»å½•æŒ‰é’®
            login_btn = await self.page.query_selector('text=ç™»å½•')
            if login_btn:
                return False
            else:
                return True
        except:
            return True
    
    async def login_with_qrcode(self):
        """ä½¿ç”¨äºŒç»´ç ç™»å½•"""
        print("\n=== å¼€å§‹ç™»å½•æµç¨‹ ===")
        await self.page.goto("https://www.xiaohongshu.com/")
        await asyncio.sleep(2)
        
        try:
            # ç‚¹å‡»ç™»å½•æŒ‰é’®
            login_btn = await self.page.query_selector('text=ç™»å½•')
            if login_btn:
                await login_btn.click()
                await asyncio.sleep(2)
                
                # æŸ¥æ‰¾äºŒç»´ç ç™»å½•æ–¹å¼
                qrcode_login = await self.page.query_selector('text=æ‰«ç ç™»å½•')
                if qrcode_login:
                    await qrcode_login.click()
                    await asyncio.sleep(2)
                    
                    print("ğŸ“± è¯·ä½¿ç”¨å°çº¢ä¹¦APPæ‰«æäºŒç»´ç ç™»å½•...")
                    print("â³ ç­‰å¾…ç™»å½•...")
                    
                    # ç­‰å¾…ç™»å½•æˆåŠŸï¼ˆæ£€æµ‹URLå˜åŒ–æˆ–ç‰¹å®šå…ƒç´ ï¼‰
                    await self.page.wait_for_url("https://www.xiaohongshu.com/", timeout=120000)
                    print("âœ“ ç™»å½•æˆåŠŸï¼")
                    
                    # ä¿å­˜cookies
                    await self.save_cookies()
                    return True
        except Exception as e:
            print(f"ç™»å½•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return False
        
        return False
    
    async def search_notes(self, keyword):
        """æœç´¢ç¬”è®°"""
        search_url = f"{Config.SEARCH_URL}?keyword={keyword}"
        print(f"\nğŸ” æ­£åœ¨æœç´¢: {keyword}")
        await self.page.goto(search_url)
        await asyncio.sleep(random.uniform(2, 4))
        
    async def scroll_and_load(self):
        """æ»šåŠ¨åŠ è½½æ›´å¤šç¬”è®°"""
        last_height = await self.page.evaluate("document.body.scrollHeight")
        
        while len(self.notes) < Config.TARGET_COUNT:
            # æ»šåŠ¨åˆ°åº•éƒ¨
            await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await asyncio.sleep(Config.SCROLL_DELAY)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹åŠ è½½
            new_height = await self.page.evaluate("document.body.scrollHeight")
            if new_height == last_height:
                # å°è¯•å‘ä¸‹æ»šåŠ¨ä¸€ç‚¹
                await self.page.evaluate("window.scrollBy(0, 500)")
                await asyncio.sleep(Config.SCROLL_DELAY)
                
                # å†æ¬¡æ£€æŸ¥
                new_height = await self.page.evaluate("document.body.scrollHeight")
                if new_height == last_height:
                    print("âš  æ²¡æœ‰æ›´å¤šå†…å®¹äº†")
                    break
            
            last_height = new_height
            print(f"ğŸ“Š å·²åŠ è½½ {len(self.notes)} ç¯‡ç¬”è®°...")
            
            # æ¯æ¬¡æ»šåŠ¨åå°è¯•æå–ç¬”è®°
            await self.extract_notes_from_page()
    
    async def extract_notes_from_page(self):
        """ä»å½“å‰é¡µé¢æå–ç¬”è®°"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰ç¬”è®°å¡ç‰‡
            note_cards = await self.page.query_selector_all('[class*="note-item"], [class*="feed-card"], article')
            
            for card in note_cards:
                if len(self.notes) >= Config.TARGET_COUNT:
                    break
                
                try:
                    # ç‚¹å‡»è¿›å…¥ç¬”è®°è¯¦æƒ…é¡µ
                    await card.click()
                    await asyncio.sleep(random.uniform(1, 2))
                    
                    # æå–æ ‡é¢˜
                    title_elem = await self.page.query_selector('h1, [class*="title"], [class*="note-title"]')
                    title = await title_elem.text_content() if title_elem else "æ— æ ‡é¢˜"
                    
                    # æå–æ­£æ–‡
                    content_elem = await self.page.query_selector('[class*="content"], [class*="note-content"], [class*="desc"]')
                    content = await content_elem.text_content() if content_elem else ""
                    
                    # æ¸…ç†æ•°æ®
                    title = title.strip()
                    content = content.strip()
                    
                    if title and content:
                        note_data = {
                            'title': title,
                            'content': content,
                            'crawl_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        }
                        
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                        if not any(n['title'] == title for n in self.notes):
                            self.notes.append(note_data)
                            print(f"âœ“ å·²é‡‡é›†ç¬¬ {len(self.notes)} ç¯‡ç¬”è®°: {title[:30]}...")
                    
                    # è¿”å›æœç´¢é¡µ
                    await self.page.go_back()
                    await asyncio.sleep(random.uniform(1, 2))
                    
                except Exception as e:
                    print(f"æå–ç¬”è®°æ—¶å‡ºé”™: {e}")
                    try:
                        await self.page.go_back()
                    except:
                        pass
                    
        except Exception as e:
            print(f"æå–é¡µé¢ç¬”è®°æ—¶å‡ºé”™: {e}")
    
    async def save_notes(self):
        """ä¿å­˜ç¬”è®°åˆ°æ–‡ä»¶"""
        os.makedirs(Config.OUTPUT_DIR, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"notes_{timestamp}.json"
        filepath = os.path.join(Config.OUTPUT_DIR, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.notes, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ“ æˆåŠŸä¿å­˜ {len(self.notes)} ç¯‡ç¬”è®°åˆ° {filepath}")
        
        # åŒæ—¶ä¿å­˜ä¸ºCSVæ ¼å¼
        csv_filename = f"notes_{timestamp}.csv"
        csv_filepath = os.path.join(Config.OUTPUT_DIR, csv_filename)
        
        import csv
        with open(csv_filepath, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=['title', 'content', 'crawl_time'])
            writer.writeheader()
            writer.writerows(self.notes)
        
        print(f"âœ“ æˆåŠŸä¿å­˜ {len(self.notes)} ç¯‡ç¬”è®°åˆ° {csv_filepath}")
    
    async def run(self):
        """è¿è¡Œçˆ¬è™«"""
        await self.init()
        
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        is_logged_in = await self.check_login_status()
        
        if not is_logged_in:
            print("æœªæ£€æµ‹åˆ°ç™»å½•çŠ¶æ€ï¼Œéœ€è¦ç™»å½•")
            login_success = await self.login_with_qrcode()
            if not login_success:
                print("âŒ ç™»å½•å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
                await self.browser.close()
                return
        else:
            print("âœ“ å·²æ£€æµ‹åˆ°ç™»å½•çŠ¶æ€")
        
        # æœç´¢ç¬”è®°
        await self.search_notes(Config.SEARCH_KEYWORD)
        
        # æ»šåŠ¨åŠ è½½å¹¶æå–ç¬”è®°
        await self.scroll_and_load()
        
        # ä¿å­˜ç»“æœ
        await self.save_notes()
        
        # æ›´æ–°cookies
        await self.save_cookies()
        
        # å…³é—­æµè§ˆå™¨
        await self.browser.close()
        print("\nâœ… çˆ¬å–å®Œæˆï¼")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("å°çº¢ä¹¦çˆ¬è™« - çœ¼é•œç›¸å…³ç¬”è®°é‡‡é›†")
    print("=" * 50)
    
    crawler = XiaohongshuCrawler()
    await crawler.run()


if __name__ == "__main__":
    asyncio.run(main())
